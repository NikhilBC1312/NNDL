{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Question 1: XOR Gate Classification**"
      ],
      "metadata": {
        "id": "1j-PLFMq3OP9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**I.**\n",
        "\n",
        "**I. Write the following in the answer sheet. (5 Marks)**\n",
        "\n",
        "• Write the Threshold function.\n",
        "\n",
        "• Write Truth table for XOR Gate.\n",
        "\n",
        "• Write the XOR Gate Classification with input with weight initialization W11 = W21 =W12 = W22 =1.\n",
        "\n",
        "• Find the Optimum weights of W11, W21, W12, W22, V1 and V2 using the threshold function.\n",
        "\n",
        "• Why does the Single Layer Perceptron struggle to classify the XOR gate?\n",
        "\n",
        "• What modifications can be made to the neural network model to handle the XOR gate correctly?"
      ],
      "metadata": {
        "id": "g5AQw3ur3OJ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**II. Implement the following:**"
      ],
      "metadata": {
        "id": "crpxqizt3qBw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "• Scenario:\n",
        "\n",
        "* The XOR gate is known for its complexity, as it outputs 1 only when the inputs are different.\n",
        "This is a challenge for a Single Layer Perceptron since XOR is not linearly separable.\n",
        "\n",
        "• Lab Task: Attempt to implement a Single Layer Perceptron in Google Colab to classify the output of an XOR gate. Perform the following steps:\n",
        "\n",
        "• Create the XOR gate's truth table dataset.\n",
        "\n",
        "• Implement the perceptron model and train it using the XOR dataset using MCP (McCulloch Pitts) Neuron.\n",
        "\n",
        "• Observe and discuss the perceptron's performance in this scenario.\n",
        "\n",
        "• Implement XOR using Multi-Layer Perceptron."
      ],
      "metadata": {
        "id": "n-_Nfn0K3xoT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsgFcuiE24Aq",
        "outputId": "1b5abf43-e31d-46d3-f14d-4362e2095b03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: [0 0] -> Predicted: [1]\n",
            "Input: [0 1] -> Predicted: [1]\n",
            "Input: [1 0] -> Predicted: [1]\n",
            "Input: [1 1] -> Predicted: [1]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# XOR Gate Inputs and Outputs\n",
        "inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "outputs = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "# Initialize weights and bias\n",
        "weights = np.random.rand(2, 1)\n",
        "bias = np.random.rand(1)\n",
        "learning_rate = 0.1\n",
        "\n",
        "# Step Activation Function (Threshold Function)\n",
        "def step_function(x):\n",
        "    return np.where(x >= 0, 1, 0)\n",
        "\n",
        "# Train the perceptron\n",
        "for epoch in range(10000):\n",
        "    weighted_sum = np.dot(inputs, weights) + bias\n",
        "    predictions = step_function(weighted_sum)\n",
        "    error = outputs - predictions\n",
        "    weights += learning_rate * np.dot(inputs.T, error)\n",
        "    bias += learning_rate * np.sum(error)\n",
        "\n",
        "# Test the perceptron\n",
        "for i in range(len(inputs)):\n",
        "    print(f\"Input: {inputs[i]} -> Predicted: {step_function(np.dot(inputs[i], weights) + bias)}\")\n",
        "\n",
        "# The Single Layer Perceptron will fail to correctly classify XOR because XOR is not linearly separable.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**2.Multi-Layer Perceptron for XOR: Implement a simple neural network with one hidden layer to correctly classify the XOR outputs.**"
      ],
      "metadata": {
        "id": "TIF90evX4Jlt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Define the MLP model\n",
        "model = Sequential()\n",
        "model.add(Dense(2, input_dim=2, activation='relu'))  # Hidden layer with 2 neurons\n",
        "model.add(Dense(1, activation='sigmoid'))  # Output layer\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(inputs, outputs, epochs=5000, verbose=0)\n",
        "\n",
        "# Test the model\n",
        "predictions = model.predict(inputs)\n",
        "print(\"Predictions:\")\n",
        "print(predictions)\n",
        "\n",
        "# Convert predictions to binary (0 or 1)\n",
        "predictions = np.round(predictions)\n",
        "print(\"Rounded Predictions:\")\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSIU41474GbM",
        "outputId": "ae13ae8f-e979-448c-c758-becae0cad2a0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Predictions:\n",
            "[[0.49977913]\n",
            " [0.4999809 ]\n",
            " [0.5000033 ]\n",
            " [0.50020504]]\n",
            "Rounded Predictions:\n",
            "[[0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]]\n"
          ]
        }
      ]
    }
  ]
}